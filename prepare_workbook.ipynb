{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/jarad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from requests import get\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import acquire "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "Lowercase everything\n",
    "Normalize unicode characters\n",
    "Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    string = string.lower()\n",
    "    string = unicodedata.normalize('NFKD', string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8')\n",
    "    string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "    return tokenizer.tokenize(string, return_str=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(string):\n",
    "    # Create the nltk stemmer object, then use it\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "    stems = [ps.stem(word) for word in string.split()]\n",
    "    string_stemmed = ' '.join(stems)\n",
    "    return string_stemmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(string):\n",
    "    #Create the nltk stemmer objest, then use it\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemms = [wnl.lemmatize(word) for word in string.split()]\n",
    "    string_lem = ''.join(lemms)\n",
    "\n",
    "    return string_lem\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    This function takes in some text, optional extra_words and exclude_words parameters\n",
    "    with default empty lists and returns the text after removing all stop words.\n",
    "    '''\n",
    "    # Create stopword_list\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # Remove 'exclude_words' from stopword_list to keep these in my text.\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "    \n",
    "    # Add in 'extra_words' to stopword_list\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    \n",
    "    # Split words in string.\n",
    "    words = string.split()\n",
    "    \n",
    "    # Create a list of words from my string with stopwords removed and assign to variable.\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    \n",
    "    # Join words in the list back into strings and assign to a variable.\n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# headers = {'User-Agent': 'Codeup Data Science'} \n",
    "   \n",
    "# soup = BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Don't eff this up: Bezos recalls warning from ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>Ahead of the debut of The Lord of the Rings' p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Snap CEO confirms 20% job cuts, says 'We must ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>In a letter to staff posted on Snap’s website,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>US sought records on Binance CEO for crypto mo...</td>\n",
       "      <td>Ashley Paul</td>\n",
       "      <td>US prosecutors sought communication records in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>Price of commercial LPG cylinders cut by up to...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>State-owned fuel retailers on Thursday announc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Chairman of Russia's 2nd largest oil firm dies...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>The chairman of Russia's second-largest oil pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>1st feedback of Dil Se was bad, exhibitors fel...</td>\n",
       "      <td>Amartya Sharma</td>\n",
       "      <td>Filmmaker Ram Gopal Varma has revealed the imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Alia Bhatt's work drives me, inspires me to do...</td>\n",
       "      <td>Amartya Sharma</td>\n",
       "      <td>Responding to a question by Karan Johar over h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Riteish, Genelia buy BMW iX electric car worth...</td>\n",
       "      <td>Kameshwari</td>\n",
       "      <td>Actor Riteish Deshmukh and his wife Genelia De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>Tiger says Rekha played Big B's mother &amp; love ...</td>\n",
       "      <td>Amartya Sharma</td>\n",
       "      <td>During the quiz round in the 'Koffee With Kara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>I wouldn't date Kartik Aaryan as I know him 't...</td>\n",
       "      <td>Arnab Mukherji</td>\n",
       "      <td>Actress Kriti Sanon said one of the reasons wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            topic                                              title  \\\n",
       "0        business  Don't eff this up: Bezos recalls warning from ...   \n",
       "1        business  Snap CEO confirms 20% job cuts, says 'We must ...   \n",
       "2        business  US sought records on Binance CEO for crypto mo...   \n",
       "3        business  Price of commercial LPG cylinders cut by up to...   \n",
       "4        business  Chairman of Russia's 2nd largest oil firm dies...   \n",
       "..            ...                                                ...   \n",
       "94  entertainment  1st feedback of Dil Se was bad, exhibitors fel...   \n",
       "95  entertainment  Alia Bhatt's work drives me, inspires me to do...   \n",
       "96  entertainment  Riteish, Genelia buy BMW iX electric car worth...   \n",
       "97  entertainment  Tiger says Rekha played Big B's mother & love ...   \n",
       "98  entertainment  I wouldn't date Kartik Aaryan as I know him 't...   \n",
       "\n",
       "             author                                            content  \n",
       "0    Ridham Gambhir  Ahead of the debut of The Lord of the Rings' p...  \n",
       "1    Ridham Gambhir  In a letter to staff posted on Snap’s website,...  \n",
       "2       Ashley Paul  US prosecutors sought communication records in...  \n",
       "3    Ridham Gambhir  State-owned fuel retailers on Thursday announc...  \n",
       "4    Ridham Gambhir  The chairman of Russia's second-largest oil pr...  \n",
       "..              ...                                                ...  \n",
       "94   Amartya Sharma  Filmmaker Ram Gopal Varma has revealed the imm...  \n",
       "95   Amartya Sharma  Responding to a question by Karan Johar over h...  \n",
       "96       Kameshwari  Actor Riteish Deshmukh and his wife Genelia De...  \n",
       "97   Amartya Sharma  During the quiz round in the 'Koffee With Kara...  \n",
       "98  Arnab Mukherji   Actress Kriti Sanon said one of the reasons wh...  \n",
       "\n",
       "[99 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run my acquire function to get the news articles. Is there an easier way?\n",
    "news_json = acquire.get_news_articles()\n",
    "\n",
    "news_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
